{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c36e6e7f",
   "metadata": {},
   "source": [
    "## Матричные нормы и числа обусловленности\n",
    "\n",
    "### План\n",
    "\n",
    "1. Задачи вычислительной линейной алгебры -> СЛАУ.\n",
    "\n",
    "2. Влияние погрешности входных данных на решение СЛАУ.\n",
    "\n",
    "3. Векторные и матричные нормы.\n",
    "\n",
    "4. Числа обусловленности.\n",
    "\n",
    "5. Прямые методы решения СЛАУ (Метод Гаусса)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca8631",
   "metadata": {},
   "source": [
    "Если будет тяжело читать такой широкий формат, то в папке семинара есть pdf-ник с этой же теорией в нормальном формате."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da83c579",
   "metadata": {},
   "source": [
    "### Задачи вычислительной линейной алгебры\n",
    "\n",
    "К задачам, решаемым численно, относятся:\n",
    "\n",
    "  - Решение систем линейных алгебраических уравнений\n",
    "\n",
    "$$\n",
    "\\mathbf{A x}=\\mathrm{f}\n",
    "$$\n",
    "\n",
    "- Вычисление определителей и обратных матриц\n",
    "\n",
    "$$\\operatorname{det} \\mathbf{A}, \\quad \\mathbf{B}=\\mathbf{A}^{-1}$$\n",
    "\n",
    "- Вычисление собственных и сингулярных чисел и векторов\n",
    "\n",
    "На практике разные вычислительные задачи приводят к необходимости решать линейные системы уравнений. С этой задачи и начнём.\n",
    "\n",
    "В этом семинаре цель - понять, какие СЛАУ можно решать хорошо, а с какими возникнут трудности вне зависимости от метода решения. Также разберём базовые методы решения СЛАУ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cfe5e1",
   "metadata": {},
   "source": [
    "### Задача СЛАУ\n",
    "\n",
    "Найти решение системы из $n$ линейных уравнений с $n$ неизвестными\n",
    "$$\n",
    "\\left\\{\\begin{array}{c}\n",
    "a_{11} x_1+a_{12} x_2+\\cdots+a_{1 n} x_n=f_1 \\\\\n",
    "a_{21} x_1+a_{22} x_2+\\cdots+a_{2 n} x_n=f_2 \\\\\n",
    "\\vdots \\\\\n",
    "a_{n 1} x_1+a_{n 2} x_2+\\cdots+a_{n n} x_n=f_n\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "для краткости записанной в матричной форме\n",
    "\n",
    "$$A x=f$$\n",
    "\n",
    "Существование и единственность решения этой системы гарантируется при $\\operatorname{det} \\mathbf{A} \\neq 0$.\n",
    "\n",
    "Конечно, алгоритм её решения в общем случае математически можно явно задать методом поиска обратной, что крайне сложно, или методом Крамера. Однако в нём требуется явный расчёт определителей матриц $\\Delta=\\sum_{i_1, i_2, \\ldots, i_n}(-1)^{P\\left(i_1, i_2, \\ldots, i_n\\right)} a_{1 i_1} a_{2 i_2} \\cdots a_{n i_n}$, которые считать крайне затратно. Фактически, сложность метода Крамера имеет асимптотику $\\mathcal{O}(n \\cdot n !)$, что сужает его применимость до матриц размера $n \\lesssim 10$. \n",
    "\n",
    "Прежде чем мы перейдём к непосредственным методам решения СЛАУ, отметим важной свойство данной задачи - СЛАУ может иметь  __критическую__ чувствительность к погрешностям коэффициентов.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74deb8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Влияние неустранимой погрешности на плохо-обусловленные системы.\n",
    "\n",
    "Проиллюстрируем её на простом примере. Пусть решается система\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{cc}\n",
    "10 & 9 \\\\\n",
    "9 & 8\n",
    "\\end{array}\\right)\\left(\\begin{array}{l}\n",
    "x_1 \\\\\n",
    "x_2\n",
    "\\end{array}\\right)=\\left(\\begin{array}{l}\n",
    "19 . \\\\\n",
    "17 .\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "причем матрица известна точно, а правая часть с погрешностью не более 3\\%. Отметим, что определитель матрицы $\\operatorname{det} \\mathbf{A}=10 \\cdot 8-9^2=-1 \\neq 0$. С точки зрения линейной алгебры, проблем при решении данной системы не должно быть.\n",
    "\n",
    "Посмотрим, на какую точность можно рассчитывать при решении системы. Для этого возьмём несколько векторов $f$ (рис. слева), отличающихся от правой части не более, чем на 3\\%, и построим все возможные решения СЛАУ для них (рис. справа).\n",
    "\n",
    "![original image](https://cdn.mathpix.com/snip/images/_SY9r480Tj2lpmH1l1mVwnP-C7xR_99bV9W1jlYXFfM.original.fullsize.png)\n",
    "\n",
    "Задача оказалась __плохо обусловленной__. Сравнительно небольшие возмущения системы уравнений привели к существенным отклонениям в решении.\n",
    "\n",
    "Обусловленность задачи _не связана_ с конкретным численным методом, это неустранимая ошибка. Существуют способы снижения погрешности, вызванной плохой обусловленностью:\n",
    "- Каким-то образом перейти к хорошо обусловленной эквивалентной системе.\n",
    "- Повысить точность определения коэффициентов СЛАУ и правой части.\n",
    "\n",
    "Плохо обусловленные системы являются обобщением понятия вырожденных систем. Системы «близкие» к вырожденным скорее всего будут плохо обусловлены.  \n",
    "\n",
    "По-хорошему нам нужен критерий \"хорошести\" матрицы $A$  и столбца свободных членов $f$, чтобы мы могли оценить, насколько вообще решение будет иметь смысл. Для этого нам понадобятся вспомнить матричные и векторные нормы.\n",
    "\n",
    "---\n",
    "\n",
    "### Векторные нормы\n",
    "\n",
    "В вычислительной математике широко распространены следующие нормы:\n",
    "- Максимальная или бесконечная норма (иногда используется название _норма Чебышёва_)\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{x}\\|_{\\infty}=\\max _i\\left|x_i\\right|\n",
    "$$\n",
    "\n",
    "- $\\ell_1$ норма (на западе используются также названия «Манхэттенская норма» и «норма такси»)\n",
    "\n",
    "$$\n",
    "\\|\\mathrm{x}\\|_1=\\sum_i\\left|x_i\\right|\\\n",
    "$$\n",
    "\n",
    "- Евклидова норма (или $\\ell_2$ норма)\n",
    "\n",
    "$$\n",
    "\\|\\mathrm{x}\\|_e=\\sqrt{(\\mathrm{x}, \\mathrm{x})} \\equiv \\sqrt{\\sum_i x_i^2}\n",
    "$$\n",
    "\n",
    "Теперь напомним некоторые важные факты про матричные нормы.\n",
    "\n",
    "### Матричные нормы\n",
    "\n",
    "Норма матрицы должна удовлетворять стандартным аксиомам нормы:\n",
    "\n",
    "- $\\|\\mathbf{A}\\|=0 \\quad \\Leftrightarrow \\quad \\mathbf{A}=\\mathbf{0}$\n",
    "  \n",
    "- $\\|\\alpha \\mathbf{A}\\|=|\\alpha|\\|\\mathbf{A}\\|, \\quad \\forall \\alpha \\in \\mathbb{R}$\n",
    "  \n",
    "- $\\|\\mathbf{A}+\\mathbf{B}\\| \\leqslant\\|\\mathbf{A}\\|+\\|\\mathbf{B}\\|$.\n",
    "\n",
    "__Определение.__ Матричная норма $\\|\\mathbf{A}\\|_{\\text{matrix}}$ называется __согласованной__ с векторной нормой $\\|\\mathrm{x}\\|_{\\text{vector}}$, если выполняется соотношение\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{y}\\|_{\\text{vector}} \\leqslant\\|\\mathbf{A}\\|_{\\text{matrix}} \\cdot\\|\\mathbf{x}\\|_{\\text{vector}}, \\quad \\text { где } \\mathbf{y}=\\mathbf{A} \\mathbf{x}\n",
    "$$\n",
    "\n",
    "В дальнейшем не будем отдельно подписывать matrix и vector нормы - если норма берётся от вектора подразумеваем векторную норму и т.д.\n",
    "\n",
    "__Определение.__ Матричная норма $\\|\\mathbf{A}\\|$ называется __субмультипликативной__, если\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{A} \\cdot \\mathbf{B}\\| \\leqslant\\|\\mathbf{A}\\| \\cdot\\|\\mathbf{B}\\|\n",
    "$$\n",
    "\n",
    "Наконец введём ключевое определение, позволяющее естественным образом создавать матричную норму из векторной.\n",
    "\n",
    "__Определение.__ Матричная норма $\\|\\mathbf{A}\\|$ называется __подчиненной__ векторной норме $\\|\\mathrm{x}\\|$, если\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{A}\\| \\equiv \\sup _{\\mathbf{x} \\neq \\mathbf{0}} \\frac{\\|\\mathbf{A} \\mathbf{x}\\|}{\\|\\mathbf{x}\\|}=\\sup _{\\|\\mathbf{x}\\|=1}\\|\\mathbf{A} \\mathbf{x}\\|\n",
    "$$\n",
    "\n",
    "Покажем, что определенные таким образом матричные нормы будут \"хорошими\".\n",
    "\n",
    "__Лемма 1.__ Если норма $\\|\\mathbf{A}\\|$ подчинена какой-то векторной норме $\\|\\mathbf{x}\\|$, то она субмультипликативна и согласована с ней.\n",
    "\n",
    "$\\Delta$\n",
    "\n",
    "1) Субмультипликативность \n",
    "\n",
    "$$\n",
    "\\|\\mathbf{A} \\cdot \\mathbf{B}\\|=\\sup _{\\mathbf{x} \\neq 0} \\frac{\\|\\mathbf{A B} \\mathbf{x}\\|}{\\|\\mathbf{x}\\|}=\\sup _{\\mathbf{B x} \\neq 0} \\frac{\\|\\mathbf{A B} \\mathbf{x}\\|}{\\|\\mathbf{x}\\|} \\leqslant \\sup _{\\mathbf{B x} \\neq 0} \\frac{\\|\\mathbf{A B} \\mathbf{x}\\|}{\\|\\mathbf{B} \\mathbf{x}\\|} \\sup _{\\mathbf{B} \\mathbf{x} \\neq 0} \\frac{\\|\\mathbf{B} \\mathbf{x}\\|}{\\|\\mathbf{x}\\|} \\leqslant\n",
    "$$\n",
    "\n",
    "Последние два супремума взяты по части множества ненулевых векторов. От увеличения множества они не уменьшатся:\n",
    "\n",
    "$$\n",
    "\\leqslant \\sup _{\\mathbf{y} \\neq 0} \\frac{\\|\\mathbf{A} \\mathbf{y}\\|}{\\|\\mathbf{y}\\|} \\sup _{\\mathbf{z} \\neq 0} \\frac{\\|\\mathbf{B} \\mathbf{z}\\|}{\\|\\mathbf{z}\\|}=\\|\\mathbf{A}\\| \\cdot\\|\\mathbf{B}\\|\n",
    "$$\n",
    "\n",
    "2) Согласованность\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{A}\\|=\\sup _{\\mathbf{x} \\neq \\mathbf{0}} \\frac{\\|\\mathbf{A} \\mathbf{x}\\|}{\\|\\mathbf{x}\\|} \\Rightarrow\\|\\mathbf{A} \\mathbf{x}\\| \\leqslant\\|\\mathbf{A}\\| \\cdot\\|\\mathbf{x}\\|\n",
    "$$\n",
    "\n",
    "Кроме этого, из-за компактности множества $\\left\\{\\mathrm{x} \\in \\mathbb{R}^n \\mid\\|\\mathrm{x}\\|=1\\right\\}$, точная верхняя грань достигается на некотором векторе $\\mathrm{x}_0 \\neq \\mathbf{0}$, то есть для него справедливо\n",
    "\n",
    "$$\n",
    "\\left\\|\\mathbf{A} \\mathbf{x}_0\\right\\|=\\|\\mathbf{A}\\| \\cdot\\left\\|\\mathbf{x}_0\\right\\|\n",
    "$$\n",
    "\n",
    "\n",
    "<div style=\"text-align: right\"> ⬛ </div>\n",
    "\n",
    "Прежде, чем мы перейдём к явному виду матричных норм для векторных норм, упомянутых ранее, введём ещё одно важное определение из линейной алгебры.\n",
    "\n",
    "__Определение.__ __Сингулярное разложение__ произвольной квадратной матрицы $\\mathbf{A}$ есть\n",
    "\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\mathbf{A}=\\mathbf{U} \\Sigma \\mathbf{V}^{\\top}, \\quad \\text { где } \\mathbf{U U}^{\\top}=\\mathbf{V} \\mathbf{V}^{\\top}=\\mathbf{E} \\\\\n",
    "\\Sigma=\\operatorname{diag}\\left(\\sigma_1, \\ldots, \\sigma_n\\right)\n",
    "\\end{gathered}\n",
    "$$\n",
    "\n",
    "Элементы матрицы $\\Sigma$ называются __сингулярными числами__. Они всегда положительны. \n",
    "\n",
    "Отметим, что для симметричных матриц сингулярные числа являются модулями собственных чисел.\n",
    "\n",
    "---\n",
    "\n",
    "### Явный вид матричных норм\n",
    "\n",
    "Приведём явный вид матричных норм, подчинённых ранее определённым векторным нормам. Для док-ва этих явных видов см. лекцию B1 или прочитайте презентацию https://onedrive.live.com/?authkey=%21AI%5FBxUIavdEebNg&cid=6B66B90A1F084CD8&id=6B66B90A1F084CD8%21715&parId=6B66B90A1F084CD8%21256&o=OneUp.\n",
    "\n",
    "- Максимальная векторная норма $\\|\\mathbf{x}\\|_{\\infty}=\\max _i\\left|x_i\\right|$\n",
    "\n",
    "\n",
    "Матричная норма, подчиненная максимальной векторной норме, имеет вид\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{A}\\|_{\\infty}=\\max _i \\sum_j\\left|a_{i j}\\right|,\n",
    "$$\n",
    "\n",
    "и достигается на векторе $\\mathrm{x}_0$, составленном из знаков строки матрицы А с максимальной суммой модулей элементов:\n",
    "\n",
    "$$\n",
    "\\left\\|\\mathbf{A} \\mathbf{x}_0\\right\\|_{\\infty}=\\|\\mathbf{A}\\|_{\\infty} \\cdot\\left\\|\\mathbf{x}_0\\right\\|_{\\infty}\n",
    "$$\n",
    "\n",
    "Т.е. максимальная матричная норма есть максимальная сумма модулей элементов в строке.\n",
    "\n",
    "---\n",
    "\n",
    "- $\\ell_1$ норма $\\|\\mathrm{x}\\|_1=\\sum_i\\left|x_i\\right|$\n",
    "\n",
    "Матричная норма, подчиненная $\\ell_1$ векторной норме, имеет вид\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{A}\\|_1=\\max _j \\sum_i\\left|a_{i j}\\right|=\\left\\|\\mathbf{A}^{\\top}\\right\\|_{\\infty},\n",
    "$$\n",
    "\n",
    "и достигается на векторе $\\mathrm{x}_0-\\mathrm{j}$-м столбце единичной матрицы:\n",
    "\n",
    "$$\n",
    "\\left\\|\\mathbf{A} \\mathbf{x}_0\\right\\|_1=\\|\\mathbf{A}\\|_1 \\cdot\\left\\|\\mathbf{x}_0\\right\\|_1\n",
    "$$\n",
    "\n",
    "Т.е. $\\ell_1$ матричная норма есть максимальная сумма модулей элементов в столбце.\n",
    "\n",
    "---\n",
    "\n",
    "- Евклидова норма $\\|\\mathrm{x}\\|_e = \\sqrt{\\sum_i x_i^2}$\n",
    "\n",
    "Евклидова норма матрицы А равна ее максимальному сингулярному числу\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{A}\\|_e=\\sigma_{\\max }(\\mathbf{A})=\\sqrt{\\lambda_{\\max }\\left(\\mathbf{A}^{\\top} \\mathbf{A}\\right)},\n",
    "$$\n",
    "\n",
    "и достигается на соответствующем правом сингулярном векторе\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_0=\\mathbf{V} \\mathbf{z}_0=\\mathbf{v}_{j_0}, \\quad \\mathbf{A}^{\\top} \\mathbf{A} \\mathbf{v}_{j_0}=\\lambda_{\\max } \\mathbf{v}_{j_0}\n",
    "$$\n",
    "\n",
    "где $j_0$ - номер максимального сингулярного числа, $\\mathbf{v}_{j_0}-j_0$-й столбец матрицы V.\n",
    "\n",
    "Как видим, необязательно считать сингулярные числа для матрицы $\\mathbf{A}$, чтобы найти её евклидову норму. Достаточно посчитать собственные числа матрицы $\\mathbf{A}^{\\top} \\mathbf{A}$, и взять из них корень.\n",
    "\n",
    "---\n",
    "\n",
    "- Норма Фробениуса\n",
    "\n",
    "Является неоператорной нормой, т.е. неподчинённой никакой векторной нормой. Приводится здесь для справки.\n",
    "\n",
    "$$\n",
    "\\|A\\|_F=\\sqrt{\\sum_{i=1}^n \\sum_{j=1}^n\\left|a_{i j}\\right|^2}\n",
    "$$\n",
    "\n",
    "Наконец, можем вернуться к оценке погрешности решения СЛАУ.\n",
    "\n",
    "---\n",
    "\n",
    "### Числа обусловленности\n",
    "\n",
    "#### Число обусловленности системы при заданной правой части\n",
    "Рассмотрим систему линейных уравнений\n",
    "\n",
    "$$\n",
    "\\mathbf{A x}=\\mathbf{f},\n",
    "$$\n",
    "\n",
    "а также систему, получающуюся из нее возмущением правой части на вектор $\\delta f$  (это не $\\delta$ умноженное на $f$, а вектор возмущения):\n",
    "\n",
    "$$\n",
    "A \\mathrm{x}^{\\prime}=\\mathrm{f}+\\delta \\mathrm{f} .\n",
    "$$\n",
    "\n",
    "В силу линейности,\n",
    "\n",
    "$$\n",
    "\\delta \\mathrm{x} \\equiv \\mathrm{x}^{\\prime}-\\mathrm{x}=\\mathbf{A}^{-1} \\delta \\mathbf{f} .\n",
    "$$\n",
    "\n",
    "Оценим относительную погрешность решения в некоторой норме\n",
    "\n",
    "$$\n",
    "\\frac{\\|\\delta \\mathbf{x}\\|}{\\|\\mathrm{x}\\|}=\\frac{\\left\\|\\mathbf{A}^{-1} \\delta \\mathbf{f}\\right\\|}{\\|\\mathrm{x}\\|} \\leqslant \\frac{\\left\\|\\mathbf{A}^{-1}\\right\\|\\|\\delta \\mathbf{f}\\|}{\\|\\mathrm{x}\\|}=\\frac{\\left\\|\\mathbf{A}^{-1}\\right\\|\\|\\mathrm{f}\\|}{\\|\\mathrm{x}\\|} \\cdot \\frac{\\|\\delta \\mathbf{f}\\|}{\\|\\mathrm{f}\\|} \n",
    "$$\n",
    "\n",
    "Считаем, что матричная норма согласована с векторной, и мы можем оценить $\\left\\|\\mathbf{A}^{-1} \\delta \\mathbf{f}\\right\\|$ сверху произведением норм $\\left\\|\\mathbf{A}^{-1}\\right\\| \\cdot\\|\\delta \\mathbf{f}\\|$.\n",
    "\n",
    "Мы получили связь между относительной погрешностью решения и относительной погрешностью правой части системы уравнений:\n",
    "\n",
    "$$\n",
    "\\frac{\\|\\delta \\mathbf{x}\\|}{\\|\\mathrm{x}\\|} \\leqslant \\frac{\\left\\|\\mathbf{A}^{-1}\\right\\|\\|\\mathrm{f}\\|}{\\|\\mathrm{x}\\|} \\cdot \\frac{\\|\\delta \\mathbf{f}\\|}{\\|\\mathrm{f}\\|} .\n",
    "$$\n",
    "\n",
    "Величина\n",
    "\n",
    "$$\n",
    "\\mathcal{V}(\\mathbf{A}, \\mathbf{f})=\\frac{\\left\\|\\mathbf{A}^{-1}\\right\\|\\|\\mathbf{f}\\|}{\\|\\mathbf{x}\\|}=\\frac{\\left\\|\\mathbf{A}^{-1}\\right\\|\\|\\mathbf{f}\\|}{\\left\\|\\mathbf{A}^{-1} \\mathbf{f}\\right\\|}\n",
    "$$\n",
    "\n",
    "называется __числом обусловленности системы при заданной правой части__ и показывает, во сколько раз может возрасти относительная погрешность решения по сравнению с погрешностью правой части при решении системы $\\mathbf{A x}=\\mathbf{f}$.\n",
    "\n",
    "Отметим, что $\\left\\|\\mathbf{A}^{-1} \\mathbf{f}\\right\\| \\leqslant\\left\\|\\mathbf{A}^{-1}\\right\\|\\|\\mathbf{f}\\|$, и число $\\mathcal{V}$ всегда не меньше единицы.\n",
    "\n",
    "__Примечание о достижении равенства__: при выводе оценки\n",
    "\n",
    "$$\n",
    "\\frac{\\|\\delta \\mathbf{x}\\|}{\\|\\mathbf{x}\\|} \\leqslant \\mathcal{V}(\\mathbf{A}, \\mathbf{f}) \\frac{\\|\\delta \\mathbf{f}\\|}{\\|\\mathbf{f}\\|}, \\quad \\mathcal{V}(\\mathbf{A}, \\mathbf{f})=\\frac{\\left\\|\\mathbf{A}^{-1}\\right\\|\\|\\mathbf{f}\\|}{\\|\\mathbf{x}\\|} .\n",
    "$$\n",
    "\n",
    "неравенство возникло из \n",
    "\n",
    "$$\n",
    "\\left\\|\\mathbf{A}^{-1} \\delta \\mathbf{f}\\right\\| \\leqslant\\left\\|\\mathbf{A}^{-1}\\right\\| \\cdot\\|\\delta \\mathbf{f}\\|,\n",
    "$$\n",
    "\n",
    "которое для подчиненных норм является точным. То есть, можно предъявить такой вектор $\\delta f$, что для него неравенство превратится в равенство, а оценка\n",
    "\n",
    "$$\n",
    "\\frac{\\|\\delta \\mathbf{x}\\|}{\\|\\mathbf{x}\\|} \\leqslant \\mathcal{V}(\\mathbf{A}, \\mathbf{f}) \\frac{\\|\\delta \\mathbf{f}\\|}{\\|\\mathbf{f}\\|}\n",
    "$$\n",
    "\n",
    "станет равенством\n",
    "\n",
    "$$\n",
    "\\frac{\\|\\delta \\mathbf{x}\\|}{\\|\\mathbf{x}\\|}=\\mathcal{V}(\\mathbf{A}, \\mathbf{f}) \\frac{\\|\\delta \\mathbf{f}\\|}{\\|\\mathbf{f}\\|} .\n",
    "$$\n",
    "\n",
    "\n",
    "#### Число обусловленности матрицы\n",
    "\n",
    "С одной стороны, число обусловленности $\\mathcal{V}(\\mathbf{A}, \\mathbf{f})$ не может быть меньше единицы (опять-таки, можно предъявить $\\mathrm{f}$, на котором $\\mathcal{V}(\\mathbf{A}, \\mathbf{f})=1)$, но может ли оно для заданной матрицы $\\mathbf{A}$ принимать сколь угодно большие значения?\n",
    "\n",
    "Найдем универсальную, не зависящую от $f$, оценку сверху числа обусловленности:\n",
    "\n",
    "$$\n",
    "\\mathcal{V}(\\mathbf{A}, \\mathbf{f}) \\leq \\sup _{\\mathbf{f} \\neq \\mathbf{0}} \\frac{\\left\\|\\mathbf{A}^{-1}\\right\\|\\|\\mathbf{f}\\|}{\\left\\|\\mathbf{A}^{-1} \\mathbf{f}\\right\\|}=\\left\\|\\mathbf{A}^{-1}\\right\\| \\sup _{\\mathbf{x} \\neq \\mathbf{0}} \\frac{\\|\\mathbf{A} \\mathbf{x}\\|}{\\|\\mathbf{x}\\|}=\\left\\|\\mathbf{A}^{-1}\\right\\| \\cdot\\|\\mathbf{A}\\| .\n",
    "$$\n",
    "\n",
    "Данная оценка достигается, когда $\\|\\mathbf{A} \\mathbf{x}\\|=\\|\\mathbf{A}\\| \\cdot\\|\\mathrm{x}\\|$.\n",
    "\n",
    "Число $\\mu(\\mathbf{A}) \\equiv\\|\\mathbf{A}\\| \\cdot\\left\\|\\mathbf{A}^{-1}\\right\\|$ называется __числом обусловленности матрицы__ и дает универсальную оценку относительной погрешности решения системы с матрицей А:\n",
    "\n",
    "$$\n",
    "\\frac{\\|\\delta \\mathbf{x}\\|}{\\|\\mathbf{x}\\|} \\leqslant \\mu(\\mathbf{A}) \\frac{\\|\\delta \\mathbf{f}\\|}{\\|\\mathbf{f}\\|}\n",
    "$$\n",
    "\n",
    "какой бы ни была правая часть $\\mathbf{f}$.\n",
    "\n",
    "Можно показать, что если возмущается не только правая часть $\\mathrm{f}$, но и сама матрица $\\mathbf{A}$, то при условии $\\left\\|\\mathbf{A}^{-1}\\right\\| \\cdot\\|\\delta \\mathbf{A}\\|<1$ верно\n",
    "\n",
    "$$\n",
    "\\frac{\\|\\delta \\mathbf{x}\\|}{\\|\\mathbf{x}\\|} \\leqslant \\frac{\\mu(\\mathbf{A})}{1-\\mu(\\mathbf{A}) \\frac{\\|\\delta \\mathbf{A}\\|}{\\|\\mathbf{A}\\|}}\\left(\\frac{\\|\\delta \\mathbf{f}\\|}{\\|\\mathbf{f}\\|}+\\frac{\\|\\delta \\mathbf{A}\\|}{\\|\\mathbf{A}\\|}\\right)\n",
    "$$\n",
    "\n",
    "Это и есть погрешность решения при погрешности коэффициентов решения. \n",
    "\n",
    "Доказательство можно найти в Петров И.Б., Лобанов А.И. Лекции по вычислительной математике, 2006, стр. 37.\n",
    "\n",
    "---\n",
    "\n",
    "### Число обусловленности для евклидовой нормы\n",
    "\n",
    "Число обусловленности $\\mu(\\mathbf{A})$ зависит от выбранной матричной нормы. Например, для евклидовой нормы $\\sigma_{\\max }\\left(\\mathbf{A}^{-1}\\right)=\\frac{1}{\\sigma_{\\min }(\\mathbf{A})}$ и число обусловленности матрицы в евклидовой норме принимает вид\n",
    "\n",
    "$$\n",
    "\\mu_e(\\mathbf{A})=\\frac{\\sigma_{\\max }(\\mathbf{A})}{\\sigma_{\\min }(\\mathbf{A})}\n",
    "$$\n",
    "\n",
    "### Число обусловленности для бесконечной и $\\ell_1$ нормы\n",
    "\n",
    "Поскольку бесконечная и $\\ell_1$ матричные нормы связаны соотношением\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{A}\\|_{\\infty}=\\left\\|\\mathbf{A}^{\\top}\\right\\|_1,\n",
    "$$\n",
    "\n",
    "аналогично оказываются связанными числа обусловленности\n",
    "\n",
    "$$\n",
    "\\mu_{\\infty}(\\mathbf{A})=\\mu_1\\left(\\mathbf{A}^{\\top}\\right)\n",
    "$$\n",
    "\n",
    "Трудность практической оценки числа обусловленности заключается в оценке нормы $\\left\\|\\mathbf{A}^{-1}\\right\\|$. Введем важное понятие диагонального преобладания.\n",
    "\n",
    "__Определение.__ Обозначим $d_i=\\left|a_{i i}\\right|-\\sum_{j \\neq i}\\left|a_{i j}\\right|$. Говорят, что матрица имеет __строгое диагональное преобладание__, если для каждой строки\n",
    "\n",
    "$$\n",
    "d_i>0 \\quad \\Leftrightarrow \\quad\\left|a_{i i}\\right|>\\sum_{j \\neq i}\\left|a_{i j}\\right|, \\quad \\forall i=1, \\ldots, n\n",
    "$$\n",
    "\n",
    "Т.е. диагональное преобладание означает, что модуль $i$-го элемента на диагональ больше суммы модулей всех остальных элементов на $i$-ой строке.\n",
    "\n",
    "__Теорема (Varah, 1974).__ Если матрица А имеет строгое диагональное преобладание, то\n",
    "\n",
    "$$\n",
    "\\left\\|\\mathbf{A}^{-1}\\right\\|_{\\infty}<\\frac{1}{\\min _i d_i}=\\frac{1}{\\min _i\\left|a_{i i}\\right|-\\sum_{j \\neq i}\\left|a_{i j}\\right|}\n",
    "$$\n",
    "\n",
    "Подставляя эту оценку в определение $\\mu_{\\infty}(\\mathbf{A})$, получаем\n",
    "\n",
    "$$\n",
    "\\mu_{\\infty}(\\mathbf{A})<\\frac{\\max _i\\left|a_{i i}\\right|+\\sum_{j \\neq i}\\left|a_{i j}\\right|}{\\min _i\\left|a_{i i}\\right|-\\sum_{j \\neq i}\\left|a_{i j}\\right|} .\n",
    "$$\n",
    "\n",
    "Аналогичная оценка для $\\mu_1(\\mathbf{A})$ получается при наличии у матрицы диагонального преобладания по столбцам.\n",
    "\n",
    "__Оценка для конкретной задачи.__\n",
    "\n",
    "Вернемся к системе\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{cc}\n",
    "10 & 9 \\\\\n",
    "9 & 8\n",
    "\\end{array}\\right)\\left(\\begin{array}{l}\n",
    "x_1 \\\\\n",
    "x_2\n",
    "\\end{array}\\right)=\\left(\\begin{array}{c}\n",
    "19 . \\\\\n",
    "17 .\n",
    "\\end{array}\\right), \\quad \\mathbf{A}^{-1}=\\frac{1}{-1}\\left(\\begin{array}{cc}\n",
    "8 & -9 \\\\\n",
    "-9 & 10\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "и посчитаем ее числа обусловленности в разных нормах:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\|\\mathbf{A}\\|_{\\infty}=&\\|\\mathbf{A}\\|_1=19, \\quad\\left\\|\\mathbf{A}^{-1}\\right\\|_{\\infty}=\\left\\|\\mathbf{A}^{-1}\\right\\|_1=19 \\\\\n",
    "& \\mu_1(\\mathbf{A})=\\mu_{\\infty}(\\mathbf{A})=19 \\cdot 19=361\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Матрица симметрична, значит\n",
    "\n",
    "$$\n",
    "\\mu_e(\\mathbf{A})=\\left|\\frac{\\lambda_{\\max }(\\mathbf{A})}{\\lambda_{\\min }(\\mathbf{A})}\\right|=\\frac{\\sqrt{82}+9}{\\sqrt{82}-9} \\approx 326 .\n",
    "$$\n",
    "\n",
    "Таким образом, погрешность в $3 \\%$ в правой части решения приводит примерно к $1000\\%$ ошибки в решении.\n",
    "\n",
    "---\n",
    "\n",
    "### Прямые методы решения СЛАУ (Гаусс)\n",
    "\n",
    "Методы решения систем алгебраических уравнений можно разделить на два класса:\n",
    "- Прямые методы. Данные методы позволяют получить точное решение задачи (без учета ошибок округления) за конечное число арифметических действий.\n",
    "- Итерационные методы или методы последовательных приближений. Позволяют вычислять последовательность векторов $\\mathrm{x}^{(n)}$, которая при $n \\rightarrow \\infty$ сходится к решению задачи. На практике используют некоторое конечное приближение в зависимости от допустимого уровня погрешности.\n",
    "\n",
    "Итерационные методы мы пока рассматривать не будем, а с прямыми всё просто - они вам уже знакомы. В качестве примера может служить метод Гаусса. Его полное описание есть здесь https://prog-cpp.ru/gauss/ (Пригодится при решении ДЗ)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30dfbe9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Задание 1\n",
    "\n",
    "Реализовать генератор матрциц, который должен поддерживать функции:\n",
    "* Генерация абсолютно случайной матрицы $n\\times m$\n",
    "* Генерация случайной диагональной матрицы $n\\times n$\n",
    "* Генерация случайной верхнетреугольной матрицы\n",
    "* Генерация случайной нижнетреугольной матрицы\n",
    "* Генерация симметричной матрицы\n",
    "* Генерация вырожденной матрицы\n",
    "* Генерация матрицы ступенчатого вида $n\\times n$ ранга $m$\n",
    "* Генерация возмущения матрицы $n\\times m$, каждый элемент которой не превосходит по модулю заданный $\\varepsilon$. Оценить величину нормы матрицы возмущений в зависимости от параметра $\\varepsilon$ (оценить верхную границу).\n",
    "\n",
    "Оценить численно вероятность того, что созданная матрица будет вырожденной для какого-либо случая выше. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f445a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализую произвольную m,n, верхнетреугольную и симметричную. Остальное на вас - вам нужно дописать функцию.\n",
    "# Не забудьте откомментировать ваши изменения в документации к функции!\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def matrix_generate(rows, columns, type_ = \"full\", eps = 0):\n",
    "    \"\"\"\n",
    "    matrix_generate(rows, columns, type_ = \"full\")\n",
    "    \n",
    "    Создаёт случайную матрицу выбранного типа. \n",
    "    \n",
    "    Если матрицу нужных размеров создать нельзя должен выдать\n",
    "    строку f\"Error with type {type_} and shape ({rows},{columns})\".\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    rows : int\n",
    "        Количество строк в создаваемой матрице.\n",
    "    columns : int\n",
    "        Количество столбцов в создаваемой матрице.\n",
    "    type_ : str, optional\n",
    "        Тип создаваемой матрицы: \"full\", \"upper_triangular\", \"symmetric\" и т.д.\n",
    "    eps: float, optional\n",
    "        Дополнительное число, использующееся при генерации для некоторых типов матриц.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray or str\n",
    "        Выдаёт матрицу нужного типа либо ошибку.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Поддерживаемые типы матриц:\n",
    "        \"full\",\"upper_triangular\",\n",
    "        \"symmetric\",\n",
    "        ...\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    A = None\n",
    "    \n",
    "    if type_ == \"full\":\n",
    "        \n",
    "        A = np.random.random(size=(rows, columns))\n",
    "        \n",
    "    elif type_ == \"upper_triangular\":\n",
    "        \n",
    "        A = np.random.random(size=(rows, columns))\n",
    "\n",
    "        for i in range(rows):\n",
    "            for j in range(columns):\n",
    "                if (i > j):\n",
    "                    A[i, j] = 0\n",
    "    \n",
    "        # Для нижнетреугольной подумайте, как сделать без циклов for :) (звёздочка)\n",
    "        \n",
    "    elif type_ == \"symmetric\":\n",
    "        \n",
    "        if rows != columns:\n",
    "            return f\"Error with type {type_} and shape ({rows},{columns})\"\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            A = np.random.random(size=(rows, columns))\n",
    "        \n",
    "            for i in range(rows):\n",
    "                for j in range(columns):\n",
    "                    if (i > j):\n",
    "                        A[i, j] = A[j, i]\n",
    "                        \n",
    "            # И эту секцую тоже перепишите без for (звёздочка). Учтите, что портить uniform распределение нельзя.\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4a39475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03384841, 0.61919166, 0.3364713 ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_generate(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "854fe98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29995132, 0.98207415, 0.06631093, 0.67538426],\n",
       "       [0.        , 0.17282236, 0.85600283, 0.43892668],\n",
       "       [0.        , 0.        , 0.74779146, 0.6375434 ],\n",
       "       [0.        , 0.        , 0.        , 0.22880741]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_generate(4, 4, type_ = \"upper_triangular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "459eb7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33660397, 0.46781743, 0.40118006],\n",
       "       [0.        , 0.0569126 , 0.96680014],\n",
       "       [0.        , 0.        , 0.23480945],\n",
       "       [0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_generate(4, 3, type_ = \"upper_triangular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81773185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92245751, 0.01676219, 0.38027917, 0.05171008],\n",
       "       [0.01676219, 0.71872591, 0.63118199, 0.71405461],\n",
       "       [0.38027917, 0.63118199, 0.62212648, 0.00229713],\n",
       "       [0.05171008, 0.71405461, 0.00229713, 0.63507353]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_generate(4, 4, type_ = \"symmetric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ecc9756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Error with type symmetric and shape (4,1)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_generate(4, 1, type_ = \"symmetric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d35873",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "\n",
    "Реализовать вычисление трех основных норм векторов (L1, L2 и максимальную) и подчиненных им матричных норм. Реализовать вычисление числа обусловленности.\n",
    "\n",
    "Примечание: для вычисления собственных значений можно использовать linalg.eigvals из модуля scipy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aaa287",
   "metadata": {},
   "source": [
    "### Задание 3\n",
    "\n",
    "Реализовать метод Гаусса приведения матрицы к ступенчатому виду. Реализовать функцию вычисления ранга матрицы. Сгенерировать вырожденные матрицы различных рангов и размеров и проверить алгоритм."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604393a6",
   "metadata": {},
   "source": [
    "### Задание 4\n",
    "Реализовать метод Гаусса решения СЛАУ. Использовать данный метод для решения систем различных размеров. Оценить скорость работы метода Гаусса (необходимое количество операций) в зависимости от размера системы аналитически и практически."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f0dad",
   "metadata": {},
   "source": [
    "### Задание 5*\n",
    "\n",
    "Сгенерировать СЛАУ (размер матрицы должен быть не менее $50\\times 50$). Решить СЛАУ методом Гаусса для различных возмущений столбца свободных членов. Оценить число обусловленности, используя полученные результаты. Вычислить число обусловленности и сравнить с численными оценками."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7536a19472fd4c7b155dfeefd0bd0374da7ccd6ca64fc4dcd8bb6a1714ff819c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
